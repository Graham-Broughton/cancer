{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.11.0\n",
      "Python Version: 3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:14:58) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_cv_attention_models import convnext\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import cv2\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "sys.path.append('..')\n",
    "from config import CFG\n",
    "CFG = CFG()\n",
    "print(f'Tensorflow Version: {tf.__version__}')\n",
    "print(f'Python Version: {sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime(\"%d-%b-%Y %H-%M-%S\")\n",
    "np.save(now, np.array([now]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute dtype: float32\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n",
    "# TPU is fast enough and has enough memory to use float32\n",
    "policy = tf.keras.mixed_precision.Policy('float32')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n",
    "print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MatplotLib Global Settings\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU\n",
      "N_REPLICAS: 1, IS_TPU: False\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', TPU.master())\n",
    "except ValueError:\n",
    "    print('Running on GPU')\n",
    "    TPU = None\n",
    "\n",
    "if TPU:\n",
    "    IS_TPU = True\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "else:\n",
    "    IS_TPU = False\n",
    "    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "N_REPLICAS = STRATEGY.num_replicas_in_sync\n",
    "print(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TPU's the dataset needs to be stored in Google Cloud\n",
    "# Retrieve the Google Cloud location of the dataset\n",
    "GCS_DS_PATH = .get_gcs_path('rsna-preprocessing-tfrecords-640x512-dataset-pub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE: 8\n"
     ]
    }
   ],
   "source": [
    "SEED = CFG.SEED\n",
    "DEBUG = False\n",
    "\n",
    "# Image dimensions\n",
    "IMG_HEIGHT = CFG.IMG_HEIGHT\n",
    "IMG_WIDTH = CFG.IMG_WIDTH\n",
    "N_CHANNELS = CFG.N_CHANNELS\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, N_CHANNELS)\n",
    "N_SAMPLES_TFRECORDS = CFG.N_SAMPLES_RECORD\n",
    "\n",
    "# Peak Learning Rate\n",
    "LR_MAX = CFG.LR_MAX * N_REPLICAS\n",
    "WD_RATIO = CFG.WD_RATIO\n",
    "\n",
    "N_WARMUP_EPOCHS = CFG.WARMUP_EPOCHS\n",
    "N_EPOCHS = CFG.EPOCHS\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = CFG.BATCH_SIZE * N_REPLICAS\n",
    "\n",
    "# Is Interactive Flag and COrresponding Verbosity Method\n",
    "IS_INTERACTIVE = False\n",
    "VERBOSE = 1 if IS_INTERACTIVE else 2\n",
    "\n",
    "# Tensorflow AUTO flag\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(f'BATCH_SIZE: {BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed all random number generators\n",
    "def seed_everything(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DataFrame\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short Tensorflow randin integer function\n",
    "def tf_rand_int(minval, maxval, dtype=tf.int64):\n",
    "    minval = tf.cast(minval, dtype)\n",
    "    maxval = tf.cast(maxval, dtype)\n",
    "    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n",
    "\n",
    "# chance of 1 in k\n",
    "def one_in(k):\n",
    "    return 0 == tf_rand_int(0, k)\n",
    "# Function to benchmark the dataset\n",
    "def benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n",
    "            if idx == 0:\n",
    "                epoch_start = time.perf_counter()\n",
    "            elif idx == 1 and epoch_num == 0:\n",
    "                image = inputs['image']\n",
    "                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        epoch_t = time.perf_counter() - epoch_start\n",
    "        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n",
    "        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n",
    "        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')\n",
    "\n",
    "# Plots a batch of images\n",
    "def show_batch(dataset, n_rows=16, n_cols=4):\n",
    "    inputs, targets = next(iter(dataset))\n",
    "    images = inputs['image'].numpy().squeeze()\n",
    "    fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(n_cols*4, n_rows*7))\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            idx = r * n_cols + c\n",
    "            # Image\n",
    "            img = images[idx]\n",
    "            axes[r, c].imshow(img)\n",
    "            # Target\n",
    "            target = targets[idx]\n",
    "            axes[r, c].set_title(f'target: {target}', fontsize=16, pad=5)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# Decodes the TFRecords\n",
    "def decode_image(record_bytes):\n",
    "    features = tf.io.parse_single_example(record_bytes, {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "    \n",
    "    # Decode PNG Image\n",
    "    image = tf.io.decode_jpeg(features['image'], channels=N_CHANNELS)\n",
    "    # Explicit reshape needed for TPU\n",
    "    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n",
    "\n",
    "    target = features['target']\n",
    "    \n",
    "    return { 'image': image }, target\n",
    "\n",
    "def augment_image(X, y):\n",
    "    image = X['image']\n",
    "    \n",
    "    # Random Brightness\n",
    "    image = tf.image.random_brightness(image, 0.10)\n",
    "    \n",
    "    # Random Contrast\n",
    "    image = tf.image.random_contrast(image, 0.90, 1.10)\n",
    "    \n",
    "    # Random JPEG Quality\n",
    "    image = tf.image.random_jpeg_quality(image, 75, 100)\n",
    "    \n",
    "    # Random crop image with maximum of 10%\n",
    "    ratio = tf.random.uniform([], 0.75, 1.00)\n",
    "    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n",
    "    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n",
    "    # Random offset for crop\n",
    "    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n",
    "    img_width_offset = 0\n",
    "    # Crop And Resize\n",
    "    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    # Clip pixel values in range [0,255] to prevent underflow/overflow\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    return { 'image': image }, y\n",
    "\n",
    "# Undersample majority class (0/negative) by randomly dropping them\n",
    "def undersample_majority(X, y):\n",
    "    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n",
    "    return y == 1 or tf.random.uniform([]) > 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRecord file paths\n",
    "TFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob('gs://kaggle-creds/tfrecords/*.tfrecords'))\n",
    "print(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "TFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\n",
    "print(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False\n",
    "    \n",
    "    # Initialize dataset with TFRecords\n",
    "    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n",
    "    \n",
    "    # Decode mapping\n",
    "    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n",
    "\n",
    "    if not val:\n",
    "        dataset = dataset.filter(undersample_majority)\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n",
    "        dataset = dataset.with_options(ignore_order)\n",
    "        if not debug:\n",
    "            dataset = dataset.shuffle(1024)\n",
    "        dataset = dataset.repeat()        \n",
    "\n",
    "    dataset = dataset.batch(bs, drop_remainder=not val)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Train/Validation datasets\n",
    "train_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\n",
    "val_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n",
    "\n",
    "TRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n",
    "VAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\n",
    "print(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, image and label statistics\n",
    "X_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\n",
    "image = X_batch['image'].numpy()\n",
    "print(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\n",
    "print(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\n",
    "print(f'image min: {image.min():.2f}, max: {image.max():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what we will be training on\n",
    "show_batch(get_dataset(TFRECORDS_TRAIN, bs=64, val=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Distribution Train With Undersampled Majority Class\n",
    "N = BATCH_SIZE\n",
    "train_labels = []\n",
    "for _, labels in tqdm(get_dataset(TFRECORDS_TRAIN, val=False).take(N), total=N):\n",
    "    train_labels += labels.numpy().tolist()\n",
    "    \n",
    "display(pd.concat((\n",
    "        pd.Series(train_labels).value_counts(normalize=True).to_frame('Train Label Ratio'),\n",
    "        pd.Series(train_labels).value_counts().to_frame('Train Label Count'),\n",
    "    ), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Distribution Validation (Unchanged)\n",
    "val_labels = []\n",
    "for _, labels in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n",
    "    val_labels += labels.numpy().tolist()\n",
    "    \n",
    "display(pd.concat((\n",
    "        pd.Series(val_labels).value_counts(normalize=True).to_frame('Val Label Ratio'),\n",
    "        pd.Series(val_labels).value_counts().to_frame('Val Label Count'),\n",
    "    ), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pF1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='pF1', **kwargs):\n",
    "        super(pF1, self).__init__(name=name, **kwargs)\n",
    "        self.tc = self.add_weight(name='tc', initializer='zeros')\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n",
    "        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n",
    "        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        if self.tc == 0 or (self.tp + self.fp) == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            precision = self.tp / (self.tp + self.fp)\n",
    "            recall = self.tp / (self.tc)\n",
    "            return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.tc.assign(0)\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    # Repeat channels to create 3 channel images required by pretrained ConvNextV2 models\n",
    "    image = tf.repeat(image, repeats=3, axis=3)\n",
    "    # Cast to float 32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Normalize with respect to ImageNet mean/std\n",
    "    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_model():\n",
    "    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n",
    "    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n",
    "\n",
    "    with STRATEGY.scope():\n",
    "        seed_everything()\n",
    "        image = tf.keras.layers.Input(shape=INPUT_SHAPE, name='image', dtype=tf.uint8)\n",
    "        image_norm = normalize(image)\n",
    "        x = convnext.ConvNeXtV2Tiny(\n",
    "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "            pretrained='imagenet21k-ft1k',\n",
    "            num_classes=0\n",
    "        )(image_norm)\n",
    "        \n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=LR_MAX, weight_decay=LR_MAX * WD_RATIO, epsilon=1e-6)\n",
    "\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        metrics = [\n",
    "            pF1(),\n",
    "            tfa.metrics.F1Score(num_classes=1, threshold=0.5),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.BinaryAccuracy(),\n",
    "        ]\n",
    "\n",
    "        model = tf.keras.Model(inputs=image, outputs=output)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# enable XLA optmizations\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler with logaritmic warmup and cosine decay\n",
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n",
    "    \n",
    "    if current_step < num_warmup_steps:\n",
    "        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n",
    "\n",
    "# Plot the learning rate scheduler\n",
    "def plot_lr_schedule(lr_schedule, epochs):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot([None] + lr_schedule + [None])\n",
    "    # X Labels\n",
    "    x = np.arange(1, epochs + 1)\n",
    "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
    "    plt.xlim([1, epochs])\n",
    "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
    "    \n",
    "    # Increase y-limit for better readability\n",
    "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
    "    \n",
    "    # Title\n",
    "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
    "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
    "    \n",
    "    # Plot Learning Rates\n",
    "    for x, val in enumerate(lr_schedule):\n",
    "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
    "            if x < len(lr_schedule) - 1:\n",
    "                if lr_schedule[x - 1] < val:\n",
    "                    ha = 'right'\n",
    "                else:\n",
    "                    ha = 'left'\n",
    "            elif x == 0:\n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha = 'left'\n",
    "            plt.plot(x + 1, val, 'o', color='black');\n",
    "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
    "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
    "    \n",
    "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
    "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n",
    "plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Learning Rate Scheduler does not update weight decay, need to do it manually in a custom callback\n",
    "class WeightDecayCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, wd_ratio=WD_RATIO):\n",
    "        self.step_counter = 0\n",
    "        self.wd_ratio = wd_ratio\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        model.optimizer.weight_decay = model.optimizer.learning_rate * self.wd_ratio\n",
    "        print(f'learning rate: {model.optimizer.learning_rate.numpy():.2e}, weight decay: {model.optimizer.weight_decay.numpy():.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on TPU!\n",
    "history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n",
    "        validation_data = val_dataset,\n",
    "        epochs = N_EPOCHS,\n",
    "        verbose = VERBOSE,\n",
    "        callbacks = [\n",
    "            lr_callback,\n",
    "            WeightDecayCallback(),\n",
    "        ],\n",
    "        class_weight = {\n",
    "            0: 1.0,\n",
    "            1: 5.0,\n",
    "        },\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datadriven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76e1a4fc2e13d6d81c96ccf65ea612680361424ca708a56e3e754f73ae5069c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
